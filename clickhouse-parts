#!/usr/bin/python3
import datetime
import os
import re
import sys
import matplotlib
import matplotlib.pyplot
import clickhouse_driver

__version__ = '0.4'

if len(sys.argv) not in [3, 4, 5, 6, 7]:
    print('''usage: clickhouse-parts HOST DBTABLE [OUTFILE] [LAYOUT] [QUANTITY] [YMAX]

Read system.parts for given db.table and visualise into OUTFILE
(defaults to out.png)

- only given server, does not extend to other cluster nodes
- uses native port 9000, default user and empty password
- separates disk names and uses different colours ('hdd' and 'default' or 'ssd')
- groups partitions if there are too many
- optional MAXPARTS sets y-axis upper limit (usefuel for comparisons)
- QUANTITY defaults to 'count()' (you might want to plot 'sum(rows)' instead)

LAYOUT defaults to normal and can be set to `big' or `cgp' (597x341)''')
    sys.exit(2)

host = sys.argv[1]
db_table = sys.argv[2]
out_file = 'out.png'
if len(sys.argv) >= 4:
    out_file = sys.argv[3]
layout = 'normal'
if len(sys.argv) >= 5:
    layout = sys.argv[4]
quantity = 'count()'
if len(sys.argv) >= 6:
    quantity = sys.argv[5]
ymax = None
if len(sys.argv) >= 7:
    ymax = int(sys.argv[6])

def parse_system_parts(host, db_table, quantity):
    parts = {}
    partitions = {}
    for (disk_name_full, level, pid_query, count) in clickhouse_driver.Client(
        host=host, port=9000, user='default', password='').execute('''
        SELECT disk_name, level, partition_id, %s
        FROM system.parts
        WHERE (database || '.' || table) = '%s'
        GROUP BY disk_name, level, partition_id
        ORDER BY disk_name, level, partition_id
        ''' % (quantity, db_table)):
        disk_name = re.match(r'[^0-9]*', disk_name_full).group(0)
        if disk_name not in parts:
            parts[disk_name] = {}
        if level not in parts[disk_name]:
            parts[disk_name][level] = {}
        try: # coarse partitions are YYYYmmdd strings
            pid = int(datetime.datetime.strptime(pid_query,
                '%Y%m%d').replace(tzinfo=datetime.timezone.utc).timestamp())
        except ValueError: # fine partitions are epoch numbers
            pid = int(pid_query)
        parts[disk_name][level][pid] = count
        if pid not in partitions:
            partitions[pid] = []
    return parts, sorted(list(partitions))

def downsample(parts, partitions, max_partitions_to_show):
    # factor = how many original partitions make a downsampled one
    dsfactor = int(len(partitions) / max_partitions_to_show) + 1
    if dsfactor == 1:
        return parts, partitions, 1

    # length = downsampled partition in partition ID units
    # note heuristic to determine partition length from fresh partitions
    l = int((int(partitions[-1]) - int(partitions[-2])) * dsfactor)

    ds = {}
    pid0 = int(partitions[0])
    partitions = {}
    for disk_name in parts:
        ds[disk_name] = {}
        for level in parts[disk_name]:
            ds[disk_name][level] = {}
            for pid in parts[disk_name][level]:

                # magic sauce: round partition ID value
                pid_ds = str(int((int(pid) - pid0) / l) * l + pid0)

                if pid_ds not in partitions:
                    partitions[pid_ds] = []
                if pid_ds not in ds[disk_name][level]:
                    ds[disk_name][level][pid_ds] = 0
                ds[disk_name][level][pid_ds] += parts[disk_name][level][pid]

    return ds, sorted(list(partitions)), dsfactor

def find_max_level(parts):
    max_level = 0
    for disk_name in parts:
        for level in parts[disk_name]:
            max_level = max([level, max_level])
    return max_level

layouts = {
    'normal': {
        'dimensions_inch': (16, 8),
        'max_partitions_to_show': 64,
    },
    'big': {
        'dimensions_inch': (64, 32),
        'max_partitions_to_show': 256,
    },
    'cgp': {
        # match Collectd Graph Panel's 597x341
        # found Debian matplotlib 3.4.1 DPI weird so using magic numbers
        'dimensions_inch': (7.05, 3.49),
        'max_partitions_to_show': 32,
    },
}

colors = {
    'default': (1.0, 0.796, 0.792),
    'ssd': (1.0, 0.796, 0.792),
    'hdd': (0.878, 1.0, 0.792)
}

def render(parts, partitions, max_level, dsfactor, host, table, out_file, layout):
    partition_length = int(partitions[-1]) - int(partitions[-2])

    matplotlib.rcParams.update({
      'font.size': 7
    })

    def make_color(disk_name, level, max_level):
        def step_function(level, max_level): # highlight initial levels
            if level <= 3:
                return 2 * level / 8.0
            else:
                return (6 + (level - 3) * 2 / (max_level - 3)) / 8.0
        (h, s, v) = matplotlib.colors.rgb_to_hsv(colors[disk_name])
        return matplotlib.colors.hsv_to_rgb((h, s,
            v * step_function(max_level - level, max_level)))

    f, a = matplotlib.pyplot.subplots(figsize=layouts[layout]['dimensions_inch'])
    a.set_title('Parts in partitions\n%s %s' % (host, table))

    # drop Tetris pieces left to right in layers organised by disk and level
    yall = {}
    w = datetime.timedelta(seconds=(partition_length * 0.85)),
    for disk_name in parts:
        for level in parts[disk_name]:
            x, h, y = [], [], []
            for pid in parts[disk_name][level]:
                count = parts[disk_name][level][pid]
                x.append(datetime.datetime.fromtimestamp(int(pid)))
                h.append(count)
                if pid not in yall:
                    yall[pid] = 0
                y.append(yall[pid])
                yall[pid] += count

            a.bar(x, h, w, y,
                color=make_color(disk_name, level, max_level),
                label=('%s level %d' % (disk_name, level)))

    if ymax:
        a.set_ylim([0, ymax])
    a.xaxis_date()
    if dsfactor > 1:
        a.set_xlabel('partition (groups of %d)' % dsfactor)
    else:
        a.set_xlabel('partition')
    a.set_ylabel(quantity)
    f.legend(loc='upper left', bbox_to_anchor=(0.13, 0.87))
    f.savefig(out_file, bbox_inches='tight')
    f.clf()
    matplotlib.pyplot.close(f)

print('parse system.parts', host, db_table)
parts, partitions = parse_system_parts(host, db_table, quantity)

parts, partitions, dsfactor = downsample(parts, partitions,
    layouts[layout]['max_partitions_to_show'])
if dsfactor > 1:
    print('partitions combined into groups of', dsfactor)

max_level = find_max_level(parts)
print('max level', max_level)

print('render', out_file, layout)
render(parts, partitions, max_level, dsfactor, db_table, host, out_file, layout)
